{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pV92-mAhWGHv",
        "shPFPtMnTyJU",
        "D5d-0EbEWD2m",
        "-Uh89mIWldDL"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d77bf96dafed4b7abfd80da1c45a381f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b33388d31b174eea8c1f74d53c944e44",
              "IPY_MODEL_122f189628944b0f85a035791c045017",
              "IPY_MODEL_3bed795a38534dcbbda0edcabfd7b31b"
            ],
            "layout": "IPY_MODEL_ebf559b96c8c4c589ad15e0d0bc51950"
          }
        },
        "b33388d31b174eea8c1f74d53c944e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d46c2a2fce334342bbabb58e714f44f3",
            "placeholder": "​",
            "style": "IPY_MODEL_da309f5bc8214b5cafb181d1527efc13",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "122f189628944b0f85a035791c045017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f662f12c2423498797bab95aa1d7047f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44fac15d71fe43dbb6d91c01db9b678b",
            "value": 48
          }
        },
        "3bed795a38534dcbbda0edcabfd7b31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7cfc75380284ae9a4e04157e02d1f1a",
            "placeholder": "​",
            "style": "IPY_MODEL_371b91504c074eec936562f8a242a016",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.99kB/s]"
          }
        },
        "ebf559b96c8c4c589ad15e0d0bc51950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46c2a2fce334342bbabb58e714f44f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da309f5bc8214b5cafb181d1527efc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f662f12c2423498797bab95aa1d7047f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44fac15d71fe43dbb6d91c01db9b678b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7cfc75380284ae9a4e04157e02d1f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "371b91504c074eec936562f8a242a016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213cda1150074c5986ed1abafbbf5de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caebc6ea49994f98a5ff2e68ffab445a",
              "IPY_MODEL_8e9d9383e88046b2bfd1373840ce61e4",
              "IPY_MODEL_93d5de0b8d4d4e73b23cec9b6acf17d5"
            ],
            "layout": "IPY_MODEL_2858c0b7526140fca4d57f003ff79deb"
          }
        },
        "caebc6ea49994f98a5ff2e68ffab445a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256434e44279475585bff4e3afcfcdef",
            "placeholder": "​",
            "style": "IPY_MODEL_62885140128e4e4c8a962bc3b1b5ce49",
            "value": "vocab.txt: 100%"
          }
        },
        "8e9d9383e88046b2bfd1373840ce61e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e5afe6eb8de4ef4967dc386f2f6c94a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84b31a402d47472fa6adb0c9ff28d452",
            "value": 231508
          }
        },
        "93d5de0b8d4d4e73b23cec9b6acf17d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc6a1b577f9472ea85c1b49141671e8",
            "placeholder": "​",
            "style": "IPY_MODEL_71b429bfca3842159159697b8dc91e65",
            "value": " 232k/232k [00:00&lt;00:00, 2.99MB/s]"
          }
        },
        "2858c0b7526140fca4d57f003ff79deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256434e44279475585bff4e3afcfcdef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62885140128e4e4c8a962bc3b1b5ce49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e5afe6eb8de4ef4967dc386f2f6c94a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b31a402d47472fa6adb0c9ff28d452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdc6a1b577f9472ea85c1b49141671e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b429bfca3842159159697b8dc91e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9272fa605df3452da3aa6040883b075c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bf8bddfed124a1ea051654578cd2df7",
              "IPY_MODEL_daf1e8e2db304bbca84852bad613828e",
              "IPY_MODEL_fcb1dbe02e784a3e85723b80d4f39e73"
            ],
            "layout": "IPY_MODEL_ec6e1ec4892b40f2bc53b4a7293272b9"
          }
        },
        "3bf8bddfed124a1ea051654578cd2df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fd114b6adcc4d89b08e89003e79fb42",
            "placeholder": "​",
            "style": "IPY_MODEL_4d167d184a5e4af08f232a767e23d1e9",
            "value": "tokenizer.json: 100%"
          }
        },
        "daf1e8e2db304bbca84852bad613828e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fde1feca9c14d82b7950bca83a2e248",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abe4002fc92e482a8369c4c436da89f7",
            "value": 466062
          }
        },
        "fcb1dbe02e784a3e85723b80d4f39e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35a38fb43a3344c4bcf6e404e448b2cd",
            "placeholder": "​",
            "style": "IPY_MODEL_6e7dc3ad698347dcbd7a16b77da7e7e2",
            "value": " 466k/466k [00:00&lt;00:00, 6.77MB/s]"
          }
        },
        "ec6e1ec4892b40f2bc53b4a7293272b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fd114b6adcc4d89b08e89003e79fb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d167d184a5e4af08f232a767e23d1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fde1feca9c14d82b7950bca83a2e248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe4002fc92e482a8369c4c436da89f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35a38fb43a3344c4bcf6e404e448b2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7dc3ad698347dcbd7a16b77da7e7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85d2a0820ce647f696eed99159c36d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e7ac9c2790e412bb265479f1db0d8f3",
              "IPY_MODEL_9b481f9b6de6494ab380d0189f44791e",
              "IPY_MODEL_ea35d283b1064987a8ccef72ad52c786"
            ],
            "layout": "IPY_MODEL_827d9bf158a44b28ad0c23b555d7b3c0"
          }
        },
        "4e7ac9c2790e412bb265479f1db0d8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff26a0ce5b740eea766131f8c2726d9",
            "placeholder": "​",
            "style": "IPY_MODEL_2bb63054c49a46acbf6c540cd49a50ff",
            "value": "config.json: 100%"
          }
        },
        "9b481f9b6de6494ab380d0189f44791e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297e3a72b5f44995912a84b4d34759e5",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d19e344bde04309bb8165f7cf6ecb0f",
            "value": 570
          }
        },
        "ea35d283b1064987a8ccef72ad52c786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f918ae83322488a8c8c81d53833eab2",
            "placeholder": "​",
            "style": "IPY_MODEL_a3fc1287743b4827b997e4b10d5827d9",
            "value": " 570/570 [00:00&lt;00:00, 38.7kB/s]"
          }
        },
        "827d9bf158a44b28ad0c23b555d7b3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff26a0ce5b740eea766131f8c2726d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb63054c49a46acbf6c540cd49a50ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "297e3a72b5f44995912a84b4d34759e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d19e344bde04309bb8165f7cf6ecb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f918ae83322488a8c8c81d53833eab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3fc1287743b4827b997e4b10d5827d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d391b7c295b4ffb8c9842b21c716b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82d46bb83b8340c789eb29ade3761c42",
              "IPY_MODEL_c992c381dc154f93ada98ca9648a1bfb",
              "IPY_MODEL_ffe51079a5cf44f89f7a1600fccda371"
            ],
            "layout": "IPY_MODEL_b9d4b36a9d694210a0f24af50aaf5708"
          }
        },
        "82d46bb83b8340c789eb29ade3761c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82505806c86e4d179a3263293ef526c8",
            "placeholder": "​",
            "style": "IPY_MODEL_92dc6d6a6e1549f798f9d4e9af7dbe37",
            "value": "model.safetensors: 100%"
          }
        },
        "c992c381dc154f93ada98ca9648a1bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68573ad36df14aa9839d906cd74ce08e",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f04f88d2d7054dd98173fca3aa4ee286",
            "value": 440449768
          }
        },
        "ffe51079a5cf44f89f7a1600fccda371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7109dbd350b4454a575f039d857643a",
            "placeholder": "​",
            "style": "IPY_MODEL_b8e0ee71a6ef403284cf6f446366d339",
            "value": " 440M/440M [00:02&lt;00:00, 231MB/s]"
          }
        },
        "b9d4b36a9d694210a0f24af50aaf5708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82505806c86e4d179a3263293ef526c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92dc6d6a6e1549f798f9d4e9af7dbe37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68573ad36df14aa9839d906cd74ce08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04f88d2d7054dd98173fca3aa4ee286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7109dbd350b4454a575f039d857643a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e0ee71a6ef403284cf6f446366d339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZahraDehghanian97/LensCraft/blob/master/Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Generation (Using LLM)"
      ],
      "metadata": {
        "id": "pV92-mAhWGHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnj6b8RI1QDq",
        "outputId": "33b49d52-45aa-41bd-8288-dee2cedeaf87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Collecting openai\n",
            "  Downloading openai-1.60.2-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading openai-1.60.2-py3-none-any.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.9\n",
            "    Uninstalling openai-1.59.9:\n",
            "      Successfully uninstalled openai-1.59.9\n",
            "Successfully installed openai-1.60.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tYT2Y7Bd0JCi"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import random\n",
        "import json\n",
        "\n",
        "# Initialize OpenAI client with your API key\n",
        "client = OpenAI(api_key=\"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\")\n",
        "\n",
        "# Parameters for generating prompts\n",
        "parameters = {\n",
        "    \"CameraVerticalAngle\": [\"low\", \"eye\", \"high\", \"overhead\", \"birdsEye\"],\n",
        "    \"ShotSize\": [\n",
        "        \"extremeCloseUp\",\n",
        "        \"closeUp\",\n",
        "        \"mediumCloseUp\",\n",
        "        \"mediumShot\",\n",
        "        \"fullShot\",\n",
        "        \"longShot\",\n",
        "        \"veryLongShot\",\n",
        "        \"extremeLongShot\",\n",
        "    ],\n",
        "    \"MovementSpeed\": [\n",
        "        \"slowToFast\",\n",
        "        \"fastToSlow\",\n",
        "        \"constant\",\n",
        "        \"stopAndGo\",\n",
        "        \"deliberateStartStop\",\n",
        "    ],\n",
        "    \"SubjectInFramePosition\": [\n",
        "        \"left\",\n",
        "        \"right\",\n",
        "        \"top\",\n",
        "        \"bottom\",\n",
        "        \"center\",\n",
        "        \"topLeft\",\n",
        "        \"topRight\",\n",
        "        \"bottomLeft\",\n",
        "        \"bottomRight\",\n",
        "        \"outerLeft\",\n",
        "        \"outerRight\",\n",
        "        \"outerTop\",\n",
        "        \"outerBottom\",\n",
        "    ],\n",
        "    \"SubjectView\": [\n",
        "        \"front\",\n",
        "        \"back\",\n",
        "        \"left\",\n",
        "        \"right\",\n",
        "        \"threeQuarterFrontLeft\",\n",
        "        \"threeQuarterFrontRight\",\n",
        "        \"threeQuarterBackLeft\",\n",
        "        \"threeQuarterBackRight\",\n",
        "    ],\n",
        "    \"CameraMovementType\": [\n",
        "        \"static\",\n",
        "        \"panLeft\",\n",
        "        \"panRight\",\n",
        "        \"tiltUp\",\n",
        "        \"tiltDown\",\n",
        "        \"dollyIn\",\n",
        "        \"dollyOut\",\n",
        "        \"truckLeft\",\n",
        "        \"truckRight\",\n",
        "        \"pedestalUp\",\n",
        "        \"pedestalDown\",\n",
        "        \"arcLeft\",\n",
        "        \"arcRight\",\n",
        "        \"craneUp\",\n",
        "        \"craneDown\",\n",
        "        \"dollyOutZoomIn\",\n",
        "        \"dollyInZoomOut\",\n",
        "        \"dutchLeft\",\n",
        "        \"dutchRight\",\n",
        "        \"follow\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Function to interact with OpenAI API\n",
        "def chat_gpt(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",  # Use the gpt-4o-mini model\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Function to generate a single diverse user prompt\n",
        "def generate_single_prompt():\n",
        "    input_params = {\n",
        "        \"CameraVerticalAngle\": random.choice(parameters[\"CameraVerticalAngle\"]),\n",
        "        \"ShotSize\": random.choice(parameters[\"ShotSize\"]),\n",
        "        \"MovementSpeed\": random.choice(parameters[\"MovementSpeed\"]),\n",
        "        \"SubjectInFramePosition\": random.choice(parameters[\"SubjectInFramePosition\"]),\n",
        "        \"SubjectView\": random.choice(parameters[\"SubjectView\"]),\n",
        "        \"CameraMovementType\": random.choice(parameters[\"CameraMovementType\"]),\n",
        "    }\n",
        "\n",
        "    # Allow random omission of some parameters\n",
        "    params_to_include = random.sample(list(input_params.keys()), random.randint(3, len(input_params)))\n",
        "    filtered_params = {key: value for key, value in input_params.items() if key in params_to_include}\n",
        "\n",
        "    # Create a dynamic and focused prompt\n",
        "    prompt = (\n",
        "        f\"You are describing a camera setup and movement. Focus only on the camera's movements, \"\n",
        "        f\"angles, framing, and motion. Here are the camera \"\n",
        "        f\"parameters to consider:\\n\\n\"\n",
        "        + \"\\n\".join([f\"- {key.replace('Camera', '').replace('InFrame', ' In Frame')} is {value}\" for key, value in filtered_params.items()])\n",
        "        + \"\\n\\n\"\n",
        "        f\"Please describe the shot naturally and realistically, using varied and human-like expressions. Be concise. \"\n",
        "    )\n",
        "\n",
        "    #print (f\"Prompt: \\n {prompt} \\n\")\n",
        "\n",
        "    # Call GPT to generate a prompt\n",
        "    user_prompt = chat_gpt(prompt)\n",
        "\n",
        "    #print (f\"Output: \\n {user_prompt} \\n\")\n",
        "    return {\"prompt\": user_prompt, \"parameters\": filtered_params}\n",
        "\n",
        "# Generate a dataset\n",
        "def generate_dataset(num_samples=10):\n",
        "    dataset = []\n",
        "    for _ in range(num_samples):\n",
        "        dataset.append(generate_single_prompt())\n",
        "    return dataset\n",
        "\n",
        "# Save the dataset\n",
        "dataset = generate_dataset()\n",
        "with open(\"focused_camera_prompts_dataset.json\", \"w\") as f:\n",
        "    json.dump(dataset, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCub9GZ4YN1j",
        "outputId": "e1218d32-a615-4b9b-dc71-92b82d982606"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['prompt', 'parameters'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def analyze_parameters(dataset_path):\n",
        "    \"\"\"\n",
        "    Load a dataset and create binary arrays indicating which parameters are present in each entry.\n",
        "\n",
        "    Args:\n",
        "        dataset_path (str): Path to the JSON dataset file\n",
        "\n",
        "    Returns:\n",
        "        list: List of binary arrays where 1 indicates parameter presence and 0 indicates absence\n",
        "    \"\"\"\n",
        "    # Define the ordered list of all possible parameters\n",
        "    all_parameters = [\n",
        "        \"CameraVerticalAngle\",\n",
        "        \"ShotSize\",\n",
        "        \"MovementSpeed\",\n",
        "        \"SubjectInFramePosition\",\n",
        "        \"SubjectView\",\n",
        "        \"CameraMovementType\"\n",
        "    ]\n",
        "\n",
        "    # Load the dataset\n",
        "    with open(dataset_path, 'r') as f:\n",
        "        dataset = json.load(f)\n",
        "\n",
        "    # Initialize the result list\n",
        "    binary_representations = []\n",
        "\n",
        "    # Process each entry in the dataset\n",
        "    for entry in dataset:\n",
        "        # Get the parameters present in this entry\n",
        "        present_parameters = entry['parameters'].keys()\n",
        "\n",
        "        # Create binary array for this entry\n",
        "        binary_array = [1 if param in present_parameters else 0 for param in all_parameters]\n",
        "        binary_representations.append(binary_array)\n",
        "\n",
        "    return binary_representations\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Analyze the dataset\n",
        "    result = analyze_parameters(\"focused_camera_prompts_dataset.json\")\n",
        "\n",
        "    # Print results with parameter names for verification\n",
        "    all_parameters = [\n",
        "        \"CameraVerticalAngle\",\n",
        "        \"ShotSize\",\n",
        "        \"MovementSpeed\",\n",
        "        \"SubjectInFramePosition\",\n",
        "        \"SubjectView\",\n",
        "        \"CameraMovementType\"\n",
        "    ]\n",
        "    mask = []\n",
        "    for i, binary_array in enumerate(result):\n",
        "        print(f\"\\nEntry {i + 1}:\")\n",
        "        print(len(dataset[i]['parameters']))\n",
        "        print(\"Parameter Presence:\")\n",
        "        for param, present in zip(all_parameters, binary_array):\n",
        "            status = \"Present\" if present == 1 else \"Absent\"\n",
        "            print(f\"{param}: {status}\")\n",
        "        print(f\"Binary representation: {binary_array}\")\n",
        "        mask.append(binary_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hln-KO9JUytH",
        "outputId": "1bbb503c-d5f1-4355-d87b-e447e9b49217"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entry 1:\n",
            "4\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Absent\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Absent\n",
            "CameraMovementType: Present\n",
            "Binary representation: [1, 0, 1, 1, 0, 1]\n",
            "\n",
            "Entry 2:\n",
            "6\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Present\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Present\n",
            "Binary representation: [1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Entry 3:\n",
            "6\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Present\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Present\n",
            "Binary representation: [1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Entry 4:\n",
            "3\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Absent\n",
            "ShotSize: Absent\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Absent\n",
            "Binary representation: [0, 0, 1, 1, 1, 0]\n",
            "\n",
            "Entry 5:\n",
            "5\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Present\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Absent\n",
            "Binary representation: [1, 1, 1, 1, 1, 0]\n",
            "\n",
            "Entry 6:\n",
            "6\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Present\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Present\n",
            "Binary representation: [1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Entry 7:\n",
            "3\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Absent\n",
            "ShotSize: Absent\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Absent\n",
            "CameraMovementType: Present\n",
            "Binary representation: [0, 0, 1, 1, 0, 1]\n",
            "\n",
            "Entry 8:\n",
            "5\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Present\n",
            "MovementSpeed: Absent\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Present\n",
            "Binary representation: [1, 1, 0, 1, 1, 1]\n",
            "\n",
            "Entry 9:\n",
            "6\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Present\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Present\n",
            "Binary representation: [1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Entry 10:\n",
            "6\n",
            "Parameter Presence:\n",
            "CameraVerticalAngle: Present\n",
            "ShotSize: Present\n",
            "MovementSpeed: Present\n",
            "SubjectInFramePosition: Present\n",
            "SubjectView: Present\n",
            "CameraMovementType: Present\n",
            "Binary representation: [1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg1WZTArZTi7",
        "outputId": "e2617d6e-04b9-448a-acf1-b3fc6deb03a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 1, 1, 0, 1],\n",
              " [1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1],\n",
              " [0, 0, 1, 1, 1, 0],\n",
              " [1, 1, 1, 1, 1, 0],\n",
              " [1, 1, 1, 1, 1, 1],\n",
              " [0, 0, 1, 1, 0, 1],\n",
              " [1, 1, 0, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Generation (Using Templates)"
      ],
      "metadata": {
        "id": "shPFPtMnTyJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CAMERA_PARAMETERS = {\n",
        "    \"CameraVerticalAngle\": {\n",
        "        \"values\": [\"low\", \"eye\", \"high\", \"overhead\", \"birdsEye\"],\n",
        "        \"synonyms\": {\n",
        "            \"low\": [\"low-angle\", \"from below\", \"upward-facing\", \"worm's eye view\", \"ground level\", \"looking up\"],\n",
        "            \"eye\": [\"eye-level\", \"neutral\", \"straight-on\", \"level view\", \"natural angle\", \"standard height\"],\n",
        "            \"high\": [\"high-angle\", \"from above\", \"downward-facing\", \"elevated view\", \"raised perspective\", \"looking down\"],\n",
        "            \"overhead\": [\"overhead\", \"from directly above\", \"top-down\", \"ceiling view\", \"direct overhead\", \"vertical down\"],\n",
        "            \"birdsEye\": [\"bird's eye\", \"aerial\", \"far overhead\", \"extreme overhead\", \"elevated overhead\", \"sky view\"]\n",
        "        }\n",
        "    },\n",
        "    \"ShotSize\": {\n",
        "        \"values\": [\n",
        "            \"extremeCloseUp\",\n",
        "            \"closeUp\",\n",
        "            \"mediumCloseUp\",\n",
        "            \"mediumShot\",\n",
        "            \"fullShot\",\n",
        "            \"longShot\",\n",
        "            \"veryLongShot\",\n",
        "            \"extremeLongShot\",\n",
        "        ],\n",
        "        \"synonyms\": {\n",
        "            \"extremeCloseUp\": [\"extreme close-up\", \"macro shot\", \"detail view\", \"intimate detail\", \"super close-up\", \"microscopic view\"],\n",
        "            \"closeUp\": [\"close-up\", \"tight shot\", \"near view\", \"facial shot\", \"intimate frame\", \"detailed view\"],\n",
        "            \"mediumCloseUp\": [\"medium close-up\", \"head and shoulders\", \"bust shot\", \"upper body frame\", \"shoulder shot\", \"partial upper body\"],\n",
        "            \"mediumShot\": [\"medium shot\", \"mid-shot\", \"waist shot\", \"half body\", \"waist-up view\", \"mid-frame\"],\n",
        "            \"fullShot\": [\"full shot\", \"full body\", \"head to toe\", \"complete view\", \"entire figure\", \"full frame\"],\n",
        "            \"longShot\": [\"long shot\", \"wide shot\", \"full view\", \"environmental view\", \"contextual shot\", \"scene-setting shot\"],\n",
        "            \"veryLongShot\": [\"very long shot\", \"very wide shot\", \"establishing shot\", \"master shot\", \"broad view\", \"expansive shot\"],\n",
        "            \"extremeLongShot\": [\"extreme long shot\", \"extreme wide\", \"panoramic view\", \"vista shot\", \"grand view\", \"epic scale\"]\n",
        "        }\n",
        "    },\n",
        "    \"MovementSpeed\": {\n",
        "        \"values\": [\n",
        "            \"slowToFast\",\n",
        "            \"fastToSlow\",\n",
        "            \"constant\",\n",
        "            \"stopAndGo\",\n",
        "            \"deliberateStartStop\",\n",
        "            \"erratic\",\n",
        "            \"pulsing\"\n",
        "        ],\n",
        "        \"synonyms\": {\n",
        "            \"slowToFast\": [\"gradually accelerating\", \"increasing speed\", \"picking up pace\", \"building momentum\", \"ramping up\", \"progressive acceleration\"],\n",
        "            \"fastToSlow\": [\"gradually decelerating\", \"decreasing speed\", \"slowing down\", \"easing to stop\", \"winding down\", \"tapering speed\"],\n",
        "            \"constant\": [\"steady\", \"uniform\", \"consistent speed\", \"unchanging pace\", \"maintained velocity\", \"even movement\"],\n",
        "            \"stopAndGo\": [\"intermittent\", \"start and stop\", \"punctuated movement\", \"staccato motion\", \"interrupted flow\", \"periodic pauses\"],\n",
        "            \"deliberateStartStop\": [\"measured pauses\", \"intentional stops\", \"rhythmic stopping\", \"choreographed pauses\", \"planned breaks\", \"controlled stops\"],\n",
        "            \"erratic\": [\"unpredictable\", \"varying\", \"irregular\", \"random speeds\", \"sporadic\", \"changeable pace\"],\n",
        "            \"pulsing\": [\"rhythmic\", \"beating\", \"oscillating\", \"cyclic motion\", \"wave-like\", \"periodic\"]\n",
        "        }\n",
        "    },\n",
        "    \"SubjectInFramePosition\": {\n",
        "        \"values\": [\n",
        "            \"left\", \"right\", \"top\", \"bottom\", \"center\",\n",
        "            \"topLeft\", \"topRight\", \"bottomLeft\", \"bottomRight\",\n",
        "            \"outerLeft\", \"outerRight\", \"outerTop\", \"outerBottom\",\n",
        "            \"offsetCenter\",\n",
        "            \"diagonal\"\n",
        "        ],\n",
        "        \"synonyms\": {\n",
        "            \"left\": [\"on the left\", \"left side\", \"left portion\", \"leftward\", \"port side\", \"left zone\"],\n",
        "            \"right\": [\"on the right\", \"right side\", \"right portion\", \"rightward\", \"starboard side\", \"right zone\"],\n",
        "            \"top\": [\"at the top\", \"upper portion\", \"top area\", \"upper zone\", \"superior position\", \"high position\"],\n",
        "            \"bottom\": [\"at the bottom\", \"lower portion\", \"bottom area\", \"lower zone\", \"inferior position\", \"low position\"],\n",
        "            \"center\": [\"in the center\", \"middle\", \"central position\", \"dead center\", \"bull's eye\", \"epicenter\"],\n",
        "            \"topLeft\": [\"upper left\", \"top left corner\", \"northwest position\", \"high left\", \"upper port\", \"northeast corner\"],\n",
        "            \"topRight\": [\"upper right\", \"top right corner\", \"northeast position\", \"high right\", \"upper starboard\", \"northwest corner\"],\n",
        "            \"bottomLeft\": [\"lower left\", \"bottom left corner\", \"southwest position\", \"low left\", \"lower port\", \"southwest corner\"],\n",
        "            \"bottomRight\": [\"lower right\", \"bottom right corner\", \"southeast position\", \"low right\", \"lower starboard\", \"southeast corner\"],\n",
        "            \"outerLeft\": [\"far left\", \"leftmost edge\", \"extreme left\", \"peripheral left\", \"margin left\", \"border left\"],\n",
        "            \"outerRight\": [\"far right\", \"rightmost edge\", \"extreme right\", \"peripheral right\", \"margin right\", \"border right\"],\n",
        "            \"outerTop\": [\"very top\", \"topmost edge\", \"extreme top\", \"peripheral top\", \"margin top\", \"border top\"],\n",
        "            \"outerBottom\": [\"very bottom\", \"bottommost edge\", \"extreme bottom\", \"peripheral bottom\", \"margin bottom\", \"border bottom\"],\n",
        "            \"offsetCenter\": [\"slightly off-center\", \"near center\", \"just off middle\", \"asymmetric center\", \"shifted center\", \"biased center\"],\n",
        "            \"diagonal\": [\"diagonal position\", \"angular placement\", \"oblique position\", \"slanted position\", \"diagonal offset\", \"cross-frame\"]\n",
        "        }\n",
        "    },\n",
        "    \"SubjectView\": {\n",
        "        \"values\": [\n",
        "            \"front\",\n",
        "            \"back\",\n",
        "            \"left\",\n",
        "            \"right\",\n",
        "            \"threeQuarterFrontLeft\",\n",
        "            \"threeQuarterFrontRight\",\n",
        "            \"threeQuarterBackLeft\",\n",
        "            \"threeQuarterBackRight\",\n",
        "            \"overhead\",\n",
        "            \"silhouette\"\n",
        "        ],\n",
        "        \"synonyms\": {\n",
        "            \"front\": [\"front view\", \"facing camera\", \"direct front\", \"head-on\", \"straight ahead\", \"forward facing\"],\n",
        "            \"back\": [\"back view\", \"from behind\", \"rear view\", \"posterior view\", \"reverse angle\", \"backing\"],\n",
        "            \"left\": [\"left side\", \"left profile\", \"from the left\", \"port side view\", \"left aspect\", \"sinistral view\"],\n",
        "            \"right\": [\"right side\", \"right profile\", \"from the right\", \"starboard side view\", \"right aspect\", \"dextral view\"],\n",
        "            \"threeQuarterFrontLeft\": [\"angled front left\", \"partial front left\", \"diagonal front left\", \"oblique front left\", \"left forward angle\", \"left front perspective\"],\n",
        "            \"threeQuarterFrontRight\": [\"angled front right\", \"partial front right\", \"diagonal front right\", \"oblique front right\", \"right forward angle\", \"right front perspective\"],\n",
        "            \"threeQuarterBackLeft\": [\"angled back left\", \"partial back left\", \"diagonal back left\", \"oblique back left\", \"left rear angle\", \"left back perspective\"],\n",
        "            \"threeQuarterBackRight\": [\"angled back right\", \"partial back right\", \"diagonal back right\", \"oblique back right\", \"right rear angle\", \"right back perspective\"],\n",
        "            \"overhead\": [\"from above\", \"top view\", \"bird's perspective\", \"downward view\", \"superior view\", \"zenith angle\"],\n",
        "            \"silhouette\": [\"shadow form\", \"outlined shape\", \"backlit profile\", \"contour view\", \"rim lit\", \"shape outline\"]\n",
        "        }\n",
        "    },\n",
        "    \"CameraMovementType\": {\n",
        "        \"values\": [\n",
        "            \"static\", \"panLeft\", \"panRight\", \"tiltUp\", \"tiltDown\",\n",
        "            \"dollyIn\", \"dollyOut\", \"truckLeft\", \"truckRight\",\n",
        "            \"pedestalUp\", \"pedestalDown\", \"arcLeft\", \"arcRight\",\n",
        "            \"craneUp\", \"craneDown\", \"dollyOutZoomIn\", \"dollyInZoomOut\",\n",
        "            \"dutchLeft\", \"dutchRight\", \"follow\",\n",
        "            \"spiral\",\n",
        "            \"snakeTrack\",\n",
        "            \"boomerang\"\n",
        "        ],\n",
        "        \"synonyms\": {\n",
        "            \"static\": [\"stationary\", \"fixed\", \"still\", \"locked off\", \"immobile\", \"stable\"],\n",
        "            \"panLeft\": [\"pan left\", \"sweep left\", \"rotate left\", \"horizontal left\", \"left scan\", \"leftward pan\"],\n",
        "            \"panRight\": [\"pan right\", \"sweep right\", \"rotate right\", \"horizontal right\", \"right scan\", \"rightward pan\"],\n",
        "            \"tiltUp\": [\"tilt upward\", \"look up\", \"angle up\", \"vertical up\", \"upward pivot\", \"ascend view\"],\n",
        "            \"tiltDown\": [\"tilt downward\", \"look down\", \"angle down\", \"vertical down\", \"downward pivot\", \"descend view\"],\n",
        "            \"dollyIn\": [\"move forward\", \"push in\", \"track forward\", \"advance\", \"forward track\", \"approach\"],\n",
        "            \"dollyOut\": [\"move backward\", \"pull out\", \"track backward\", \"retreat\", \"backward track\", \"withdraw\"],\n",
        "            \"truckLeft\": [\"slide left\", \"track left\", \"lateral left\", \"crab left\", \"sideways left\", \"parallel left\"],\n",
        "            \"truckRight\": [\"slide right\", \"track right\", \"lateral right\", \"crab right\", \"sideways right\", \"parallel right\"],\n",
        "            \"pedestalUp\": [\"raise up\", \"elevate\", \"lift up\", \"vertical rise\", \"upward boost\", \"ascend\"],\n",
        "            \"pedestalDown\": [\"lower down\", \"descend\", \"move down\", \"vertical drop\", \"downward sink\", \"descend\"],\n",
        "            \"arcLeft\": [\"curve left\", \"orbit left\", \"circular left\", \"left circle\", \"rounded left\", \"left orbit\"],\n",
        "            \"arcRight\": [\"curve right\", \"orbit right\", \"circular right\", \"right circle\", \"rounded right\", \"right orbit\"],\n",
        "            \"craneUp\": [\"boom up\", \"jib up\", \"rise up\", \"sweep up\", \"ascending arc\", \"upward boom\"],\n",
        "            \"craneDown\": [\"boom down\", \"jib down\", \"lower\", \"sweep down\", \"descending arc\", \"downward boom\"],\n",
        "            \"dollyOutZoomIn\": [\"pull back and zoom\", \"compensating pullback\", \"contra-zoom out\", \"reverse dolly zoom\", \"backward zoom\", \"vertigo effect\"],\n",
        "            \"dollyInZoomOut\": [\"push in and zoom out\", \"compensating push\", \"contra-zoom in\", \"forward dolly zoom\", \"forward zoom\", \"inverse vertigo\"],\n",
        "            \"dutchLeft\": [\"roll left\", \"tilt left\", \"diagonal left\", \"left rotation\", \"left cant\", \"oblique left\"],\n",
        "            \"dutchRight\": [\"roll right\", \"tilt right\", \"diagonal right\", \"right rotation\", \"right cant\", \"oblique right\"],\n",
        "            \"follow\": [\"track subject\", \"maintain follow\", \"chase movement\", \"pursuit shot\", \"accompany motion\", \"shadow movement\"],\n",
        "            \"spiral\": [\"helical movement\", \"corkscrew motion\", \"spiral track\", \"circular descent\", \"winding path\", \"coil movement\"],\n",
        "            \"snakeTrack\": [\"serpentine movement\", \"winding track\", \"meandering motion\", \"curved path\", \"s-curve movement\", \"flowing track\"],\n",
        "            \"boomerang\": [\"return movement\", \"back-and-forth\", \"pendulum motion\", \"swing track\", \"reversing path\", \"loop movement\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "PROMPT_TEMPLATES = [\n",
        "    \"Capture a {shot_size} shot from a {angle} angle, with the subject positioned {frame_position} and viewed from the {subject_view}. The camera {movement_type} {movement_speed}.\",\n",
        "\n",
        "    \"From a {angle} perspective, execute a {shot_size} with the subject {frame_position} in frame, showing their {subject_view}. Use a {movement_type} movement at a {movement_speed} pace.\",\n",
        "\n",
        "    \"Position the camera for a {angle} {shot_size}, placing the subject {frame_position} and capturing their {subject_view}. The shot should {movement_type} {movement_speed}.\",\n",
        "\n",
        "    \"Execute a dynamic {shot_size} that {movement_type} {movement_speed}, maintaining a {angle} perspective of the subject's {subject_view} while positioned {frame_position}.\",\n",
        "\n",
        "    \"Frame the subject {frame_position} using a {shot_size}, emphasizing their {subject_view} from a {angle} vantage point. The camera should {movement_type} {movement_speed}.\",\n",
        "\n",
        "    \"Create a {movement_speed} sequence using a {shot_size}, keeping the subject {frame_position} as the camera {movement_type}. Maintain a {angle} angle to showcase the {subject_view}.\",\n",
        "\n",
        "    \"Design a {angle} composition with a {shot_size}, featuring the subject's {subject_view} {frame_position} in frame. Implement a {movement_speed} {movement_type} movement.\",\n",
        "\n",
        "    \"Orchestrate a {movement_speed} {movement_type} movement while maintaining a {shot_size} from a {angle} angle. Position the subject {frame_position}, highlighting their {subject_view}.\",\n",
        "\n",
        "    \"Construct a {shot_size} that reveals the subject's {subject_view} from a {angle} perspective, with the frame composition {frame_position}. Execute a {movement_speed} {movement_type}.\",\n",
        "\n",
        "    \"Chart a {movement_speed} {movement_type} trajectory using a {shot_size}, capturing the subject's {subject_view} from a {angle} angle while positioned {frame_position}.\"\n",
        "]"
      ],
      "metadata": {
        "id": "48FpXYWMcCqA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from itertools import product\n",
        "import json\n",
        "\n",
        "\n",
        "def generate_prompt(template):\n",
        "    \"\"\"Generate a single prompt by filling in the template with randomly selected parameters\"\"\"\n",
        "    params = {}\n",
        "    original_params = {}\n",
        "\n",
        "    for param_name, param_data in CAMERA_PARAMETERS.items():\n",
        "        value = random.choice(param_data[\"values\"])\n",
        "        synonym = random.choice(param_data[\"synonyms\"][value])\n",
        "\n",
        "        params[param_name.lower()] = synonym\n",
        "        original_params[param_name] = value\n",
        "\n",
        "    template_params = {\n",
        "        \"angle\": params[\"cameraverticalangle\"],\n",
        "        \"shot_size\": params[\"shotsize\"],\n",
        "        \"movement_type\": params[\"cameramovementtype\"],\n",
        "        \"movement_speed\": params[\"movementspeed\"],\n",
        "        \"frame_position\": params[\"subjectinframeposition\"],\n",
        "        \"subject_view\": params[\"subjectview\"]\n",
        "    }\n",
        "\n",
        "    prompt = template.format(**template_params)\n",
        "\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"parameters\": original_params\n",
        "    }\n",
        "\n",
        "def generate_dataset(num_samples=1000):\n",
        "    \"\"\"Generate a dataset of prompts with their corresponding parameters\"\"\"\n",
        "    dataset = []\n",
        "    for _ in range(num_samples):\n",
        "        template = random.choice(PROMPT_TEMPLATES)\n",
        "        entry = generate_prompt(template)\n",
        "        dataset.append(entry)\n",
        "    return dataset\n",
        "\n",
        "# Generate and save the dataset\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = generate_dataset(10000)\n",
        "\n",
        "    with open(\"generated_camera_prompts.json\", \"w\") as f:\n",
        "        json.dump(dataset, f, indent=2)\n",
        "\n",
        "    print(\"\\nExample generated prompts:\")\n",
        "    for i in range(3):\n",
        "        print(f\"\\nPrompt {i+1}:\")\n",
        "        print(\"Text:\", dataset[i][\"prompt\"])\n",
        "        print(\"Parameters:\", dataset[i][\"parameters\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBKAcq_1T1Ub",
        "outputId": "e093c272-3687-4014-dbfc-c01cdaa72430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example generated prompts:\n",
            "\n",
            "Prompt 1:\n",
            "Text: Orchestrate a tapering speed left scan movement while maintaining a complete view from a worm's eye view angle. Position the subject in the center, highlighting their diagonal front right.\n",
            "Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'fullShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'panLeft'}\n",
            "\n",
            "Prompt 2:\n",
            "Text: From a ceiling view perspective, execute a broad view with the subject lower portion in frame, showing their partial front right. Use a inverse vertigo movement at a even movement pace.\n",
            "Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "\n",
            "Prompt 3:\n",
            "Text: Frame the subject margin bottom using a very long shot, emphasizing their right front perspective from a ground level vantage point. The camera should downward pivot uniform.\n",
            "Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'tiltDown'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate a Dataset with Random Number Parameter"
      ],
      "metadata": {
        "id": "tGsU22rpbdkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "\n",
        "# Expanded template components with more natural variations\n",
        "TEMPLATE_COMPONENTS = {\n",
        "    \"angle\": [\n",
        "        \"from a {angle} angle\",\n",
        "        \"with a {angle} perspective\",\n",
        "        \"maintaining a {angle} view\",\n",
        "        \"using a {angle} vantage point\",\n",
        "        \"positioned at a {angle} level\",\n",
        "        \"set up with a {angle} viewpoint\",\n",
        "        \"utilizing a {angle} camera position\",\n",
        "        \"with the camera {angle}\",\n",
        "        \"capturing from {angle}\",\n",
        "        \"at a {angle} height\"\n",
        "    ],\n",
        "    \"shot_size\": [\n",
        "        \"capture a {shot_size}\",\n",
        "        \"frame a {shot_size}\",\n",
        "        \"execute a {shot_size}\",\n",
        "        \"create a {shot_size} shot\",\n",
        "        \"compose a {shot_size}\",\n",
        "        \"establish a {shot_size}\",\n",
        "        \"set up a {shot_size}\",\n",
        "        \"design a {shot_size} composition\",\n",
        "        \"deliver a {shot_size}\",\n",
        "        \"aim for a {shot_size}\"\n",
        "    ],\n",
        "    \"movement_type_and_speed\": [\n",
        "        \"as the camera {movement_type} {movement_speed}\",\n",
        "        \"with a {movement_speed} {movement_type} movement\",\n",
        "        \"using a {movement_type} motion at {movement_speed} pace\",\n",
        "        \"implementing a {movement_speed} {movement_type}\",\n",
        "        \"executing a {movement_speed} {movement_type}\",\n",
        "        \"performing a {movement_type} at {movement_speed}\",\n",
        "        \"following through with a {movement_speed} {movement_type}\",\n",
        "        \"{movement_type} the camera {movement_speed}\",\n",
        "        \"moving {movement_speed} in a {movement_type} pattern\",\n",
        "        \"with camera movement {movement_type} at {movement_speed}\"\n",
        "    ],\n",
        "    \"frame_position\": [\n",
        "        \"with the subject positioned {frame_position}\",\n",
        "        \"keeping the subject {frame_position} in frame\",\n",
        "        \"placing the subject {frame_position}\",\n",
        "        \"maintaining the subject {frame_position}\",\n",
        "        \"featuring the subject {frame_position}\",\n",
        "        \"with subject placement {frame_position}\",\n",
        "        \"composing the subject {frame_position}\",\n",
        "        \"arranging the subject {frame_position}\",\n",
        "        \"positioning our focus {frame_position}\",\n",
        "        \"with the main element {frame_position}\"\n",
        "    ],\n",
        "    \"subject_view\": [\n",
        "        \"showing their {subject_view}\",\n",
        "        \"capturing their {subject_view}\",\n",
        "        \"emphasizing their {subject_view}\",\n",
        "        \"highlighting their {subject_view}\",\n",
        "        \"revealing their {subject_view}\",\n",
        "        \"displaying the {subject_view}\",\n",
        "        \"featuring their {subject_view}\",\n",
        "        \"presenting the {subject_view}\",\n",
        "        \"focusing on their {subject_view}\",\n",
        "        \"accentuating the {subject_view}\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Opening phrases to add variety\n",
        "OPENING_PHRASES = [\n",
        "    \"The shot requires\",\n",
        "    \"Set up\",\n",
        "    \"The scene calls for\",\n",
        "    \"We need\",\n",
        "    \"This shot demands\",\n",
        "    \"Let's capture\",\n",
        "    \"Plan to get\",\n",
        "    \"The sequence needs\",\n",
        "    \"We're looking for\",\n",
        "    \"Arrange\",\n",
        "    \"Position the camera to\",\n",
        "    \"The frame should\",\n",
        "    \"We want to\",\n",
        "    \"The goal is to\",\n",
        "    \"Focus on\"\n",
        "]\n",
        "\n",
        "# Connecting phrases for more natural flow\n",
        "CONNECTING_PHRASES = [\n",
        "    \"while\",\n",
        "    \"as\",\n",
        "    \"and\",\n",
        "    \", then\",\n",
        "    \". Also,\",\n",
        "    \". Meanwhile,\",\n",
        "    \", with\",\n",
        "    \". At the same time,\",\n",
        "    \". Additionally,\",\n",
        "    \", making sure to\"\n",
        "]\n",
        "\n",
        "def generate_dynamic_template(num_params):\n",
        "    \"\"\"Generate a more natural template with a specific number of parameters\"\"\"\n",
        "    param_mapping = {\n",
        "        \"CameraVerticalAngle\": \"angle\",\n",
        "        \"ShotSize\": \"shot_size\",\n",
        "        \"MovementSpeed\": \"movement_type_and_speed\",\n",
        "        \"CameraMovementType\": \"movement_type_and_speed\",\n",
        "        \"SubjectInFramePosition\": \"frame_position\",\n",
        "        \"SubjectView\": \"subject_view\"\n",
        "    }\n",
        "\n",
        "    # Select random parameters\n",
        "    available_params = list(set(param_mapping.keys()) - {\"MovementSpeed\"})\n",
        "    selected_params = random.sample(available_params,\n",
        "                                  min(num_params, len(available_params)))\n",
        "\n",
        "    if \"CameraMovementType\" in selected_params:\n",
        "        selected_params.append(\"MovementSpeed\")\n",
        "\n",
        "    # Build template with more natural language structure\n",
        "    template_parts = []\n",
        "    used_components = set()\n",
        "\n",
        "    # Randomly decide whether to use an opening phrase\n",
        "    if random.random() < 0.7:  # 70% chance to use opening phrase\n",
        "        template_parts.append(random.choice(OPENING_PHRASES))\n",
        "\n",
        "    # Generate component parts\n",
        "    component_parts = []\n",
        "    for param in selected_params:\n",
        "        component_key = param_mapping[param]\n",
        "        if component_key not in used_components:\n",
        "            if component_key == \"movement_type_and_speed\":\n",
        "                if random.random() < 0.5:\n",
        "                    component_parts.append(random.choice(TEMPLATE_COMPONENTS[component_key]))\n",
        "            else:\n",
        "                component_parts.append(random.choice(TEMPLATE_COMPONENTS[component_key]))\n",
        "            used_components.add(component_key)\n",
        "\n",
        "    # Randomly arrange components with connecting phrases\n",
        "    while component_parts:\n",
        "        template_parts.append(component_parts.pop(random.randint(0, len(component_parts)-1)))\n",
        "        if component_parts and random.random() < 0.7:  # 70% chance to add connector\n",
        "            template_parts.append(random.choice(CONNECTING_PHRASES))\n",
        "\n",
        "    # Join all parts and clean up any double spaces or awkward punctuation\n",
        "    template = \" \".join(template_parts)\n",
        "    template = template.replace(\" ,\", \",\")\n",
        "    template = template.replace(\"  \", \" \")\n",
        "    template = template.strip()\n",
        "\n",
        "    # Ensure proper ending punctuation\n",
        "    if not template.endswith((\".\",\"!\")):\n",
        "        template += \".\"\n",
        "\n",
        "    return template, selected_params\n",
        "\n",
        "def generate_prompt(num_params):\n",
        "    \"\"\"Generate a single prompt with specified number of parameters\"\"\"\n",
        "    template, selected_params = generate_dynamic_template(num_params)\n",
        "\n",
        "    params = {}\n",
        "    original_params = {}\n",
        "\n",
        "    # Generate values only for selected parameters\n",
        "    for param_name in selected_params:\n",
        "        value = random.choice(CAMERA_PARAMETERS[param_name][\"values\"])\n",
        "        synonym = random.choice(CAMERA_PARAMETERS[param_name][\"synonyms\"][value])\n",
        "\n",
        "        params[param_name.lower()] = synonym\n",
        "        original_params[param_name] = value\n",
        "\n",
        "    # Prepare template parameters\n",
        "    template_params = {\n",
        "        \"angle\": params.get(\"cameraverticalangle\", \"\"),\n",
        "        \"shot_size\": params.get(\"shotsize\", \"\"),\n",
        "        \"movement_type\": params.get(\"cameramovementtype\", \"\"),\n",
        "        \"movement_speed\": params.get(\"movementspeed\", \"\"),\n",
        "        \"frame_position\": params.get(\"subjectinframeposition\", \"\"),\n",
        "        \"subject_view\": params.get(\"subjectview\", \"\")\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        prompt = template.format(**template_params)\n",
        "        # Clean up any potential double spaces\n",
        "        prompt = \" \".join(prompt.split())\n",
        "    except KeyError as e:\n",
        "        print(f\"Template error: {e}\")\n",
        "        print(f\"Template: {template}\")\n",
        "        print(f\"Params: {template_params}\")\n",
        "        return None\n",
        "\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"parameters\": original_params,\n",
        "        \"template\": template\n",
        "    }\n",
        "\n",
        "def generate_dataset(num_samples=1000):\n",
        "    \"\"\"Generate a dataset of prompts with varying numbers of parameters\"\"\"\n",
        "    dataset = []\n",
        "    for _ in range(num_samples):\n",
        "        # Randomly select number of parameters (3 to 6)\n",
        "        num_params = random.randint(3, 6)\n",
        "        entry = generate_prompt(num_params)\n",
        "        if entry:\n",
        "            dataset.append(entry)\n",
        "    return dataset\n",
        "\n",
        "# Generate and save the dataset\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = generate_dataset(10)\n",
        "\n",
        "    with open(\"generated_variable_camera_prompts.json\", \"w\") as f:\n",
        "        json.dump(dataset, f, indent=2)\n",
        "\n",
        "    print(\"\\nExample generated prompts:\")\n",
        "    for i in range(min(3, len(dataset))):\n",
        "        print(f\"\\nPrompt {i+1}:\")\n",
        "        print(\"Text:\", dataset[i][\"prompt\"])\n",
        "        print(\"Parameters:\", dataset[i][\"parameters\"])\n",
        "        print(\"Template:\", dataset[i][\"template\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLENGMK9bc_r",
        "outputId": "3e664e47-5b03-4521-b282-48ecfca3dbce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example generated prompts:\n",
            "\n",
            "Prompt 1:\n",
            "Text: Focus on create a detailed view shot, making sure to accentuating the shadow form . Also, with the camera elevated overhead as maintaining the subject leftward.\n",
            "Parameters: {'CameraMovementType': 'dollyOut', 'SubjectView': 'silhouette', 'SubjectInFramePosition': 'left', 'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'closeUp', 'MovementSpeed': 'constant'}\n",
            "Template: Focus on create a {shot_size} shot, making sure to accentuating the {subject_view} . Also, with the camera {angle} as maintaining the subject {frame_position}.\n",
            "\n",
            "Prompt 2:\n",
            "Text: with the camera looking up, with composing the subject lower right . Meanwhile, highlighting their angled back right design a mid-shot composition.\n",
            "Parameters: {'SubjectView': 'threeQuarterBackRight', 'SubjectInFramePosition': 'bottomRight', 'ShotSize': 'mediumShot', 'CameraMovementType': 'dutchLeft', 'CameraVerticalAngle': 'low', 'MovementSpeed': 'erratic'}\n",
            "Template: with the camera {angle}, with composing the subject {frame_position} . Meanwhile, highlighting their {subject_view} design a {shot_size} composition.\n",
            "\n",
            "Prompt 3:\n",
            "Text: Plan to get with the camera looking up while with the main element inferior position compose a vista shot . Meanwhile, presenting the rim lit.\n",
            "Parameters: {'CameraVerticalAngle': 'low', 'CameraMovementType': 'dutchLeft', 'SubjectInFramePosition': 'bottom', 'ShotSize': 'extremeLongShot', 'SubjectView': 'silhouette', 'MovementSpeed': 'fastToSlow'}\n",
            "Template: Plan to get with the camera {angle} while with the main element {frame_position} compose a {shot_size} . Meanwhile, presenting the {subject_view}.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training (BERT)"
      ],
      "metadata": {
        "id": "D5d-0EbEWD2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "with open(\"generated_camera_prompts.json\", \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Extract prompts and parameters\n",
        "prompts = [item[\"prompt\"] for item in dataset]\n",
        "parameters = [item[\"parameters\"] for item in dataset]\n",
        "\n",
        "# Define all possible parameter keys and values\n",
        "parameter_keys = {\n",
        "    \"CameraVerticalAngle\": [\"low\", \"eye\", \"high\", \"overhead\", \"birdsEye\"],\n",
        "    \"ShotSize\": [\n",
        "        \"extremeCloseUp\",\n",
        "        \"closeUp\",\n",
        "        \"mediumCloseUp\",\n",
        "        \"mediumShot\",\n",
        "        \"fullShot\",\n",
        "        \"longShot\",\n",
        "        \"veryLongShot\",\n",
        "        \"extremeLongShot\",\n",
        "    ],\n",
        "    \"MovementSpeed\": [\n",
        "        \"slowToFast\",\n",
        "        \"fastToSlow\",\n",
        "        \"constant\",\n",
        "        \"stopAndGo\",\n",
        "        \"deliberateStartStop\",\n",
        "    ],\n",
        "    \"SubjectInFramePosition\": [\n",
        "        \"left\",\n",
        "        \"right\",\n",
        "        \"top\",\n",
        "        \"bottom\",\n",
        "        \"center\",\n",
        "        \"topLeft\",\n",
        "        \"topRight\",\n",
        "        \"bottomLeft\",\n",
        "        \"bottomRight\",\n",
        "        \"outerLeft\",\n",
        "        \"outerRight\",\n",
        "        \"outerTop\",\n",
        "        \"outerBottom\",\n",
        "    ],\n",
        "    \"SubjectView\": [\n",
        "        \"front\",\n",
        "        \"back\",\n",
        "        \"left\",\n",
        "        \"right\",\n",
        "        \"threeQuarterFrontLeft\",\n",
        "        \"threeQuarterFrontRight\",\n",
        "        \"threeQuarterBackLeft\",\n",
        "        \"threeQuarterBackRight\",\n",
        "    ],\n",
        "    \"CameraMovementType\": [\n",
        "        \"static\",\n",
        "        \"panLeft\",\n",
        "        \"panRight\",\n",
        "        \"tiltUp\",\n",
        "        \"tiltDown\",\n",
        "        \"dollyIn\",\n",
        "        \"dollyOut\",\n",
        "        \"truckLeft\",\n",
        "        \"truckRight\",\n",
        "        \"pedestalUp\",\n",
        "        \"pedestalDown\",\n",
        "        \"arcLeft\",\n",
        "        \"arcRight\",\n",
        "        \"craneUp\",\n",
        "        \"craneDown\",\n",
        "        \"dollyOutZoomIn\",\n",
        "        \"dollyInZoomOut\",\n",
        "        \"dutchLeft\",\n",
        "        \"dutchRight\",\n",
        "        \"follow\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# One-hot encode parameters\n",
        "def encode_parameters(parameters):\n",
        "    encoded = []\n",
        "    for key, values in parameter_keys.items():\n",
        "        vec = [0] * len(values)\n",
        "        if key in parameters and parameters[key] in values:\n",
        "            vec[values.index(parameters[key])] = 1\n",
        "        encoded.extend(vec)\n",
        "    return encoded\n",
        "\n",
        "encoded_parameters = np.array([encode_parameters(p) for p in parameters])\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(prompts, encoded_parameters, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a custom dataset\n",
        "class CameraDataset(Dataset):\n",
        "    def __init__(self, prompts, labels, tokenizer, max_length=128):\n",
        "        self.prompts = prompts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prompt = self.prompts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(prompt, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "        return encoding[\"input_ids\"].squeeze(0), encoding[\"attention_mask\"].squeeze(0), torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = CameraDataset(X_train, y_train, tokenizer)\n",
        "test_dataset = CameraDataset(X_test, y_test, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define the model\n",
        "class CameraPredictor(nn.Module):\n",
        "    def __init__(self, bert_model, num_labels):\n",
        "        super(CameraPredictor, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(bert_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.dropout(pooled_output)\n",
        "        return torch.sigmoid(self.fc(x))\n",
        "\n",
        "# Instantiate the model\n",
        "num_labels = y_train.shape[1]\n",
        "model = CameraPredictor(bert_model, num_labels)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "def calculate_accuracy(outputs, labels, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate accuracy for multi-label classification\n",
        "    \"\"\"\n",
        "    predictions = (outputs > threshold).float()\n",
        "    correct_predictions = (predictions == labels).float()\n",
        "    accuracy = correct_predictions.mean().item()\n",
        "    return accuracy\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=5):\n",
        "    best_val_accuracy = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_accuracy = 0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        for input_ids, attention_mask, labels in train_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            batch_accuracy = calculate_accuracy(outputs, labels)\n",
        "            train_accuracy += batch_accuracy\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "\n",
        "        avg_train_loss = train_loss / num_train_batches\n",
        "        avg_train_accuracy = train_accuracy / num_train_batches\n",
        "\n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        test_accuracy = 0\n",
        "        num_test_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for input_ids, attention_mask, labels in test_loader:\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                batch_accuracy = calculate_accuracy(outputs, labels)\n",
        "                test_accuracy += batch_accuracy\n",
        "                test_loss += loss.item()\n",
        "                num_test_batches += 1\n",
        "\n",
        "        avg_test_loss = test_loss / num_test_batches\n",
        "        avg_test_accuracy = test_accuracy / num_test_batches\n",
        "\n",
        "        # Track best validation accuracy\n",
        "        if avg_test_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = avg_test_accuracy\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        print(f\"Training Loss: {avg_train_loss:.4f}, Training Accuracy: {avg_train_accuracy:.4f}\")\n",
        "        print(f\"Validation Loss: {avg_test_loss:.4f}, Validation Accuracy: {avg_test_accuracy:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "# Predict function with accuracy calculation\n",
        "def predict(prompt, return_raw=False):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(prompt, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask).cpu().numpy()[0]\n",
        "\n",
        "    if return_raw:\n",
        "        return outputs\n",
        "\n",
        "    predicted_params = {}\n",
        "    start_idx = 0\n",
        "    for key, values in parameter_keys.items():\n",
        "        end_idx = start_idx + len(values)\n",
        "        predicted_value_idx = np.argmax(outputs[start_idx:end_idx])\n",
        "        if outputs[start_idx:end_idx][predicted_value_idx] > 0.1:\n",
        "            predicted_params[key] = values[predicted_value_idx]\n",
        "        start_idx = end_idx\n",
        "    return predicted_params\n",
        "\n",
        "# Test predictions with detailed metrics\n",
        "def evaluate_predictions(model, test_loader, threshold=0.5):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, labels in test_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            predictions = (outputs > threshold).float()\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Calculate accuracy per parameter type\n",
        "    start_idx = 0\n",
        "    print(\"\\nAccuracy by Parameter Type:\")\n",
        "    for key, values in parameter_keys.items():\n",
        "        end_idx = start_idx + len(values)\n",
        "        parameter_accuracy = calculate_accuracy(\n",
        "            torch.tensor(all_predictions[:, start_idx:end_idx]),\n",
        "            torch.tensor(all_labels[:, start_idx:end_idx])\n",
        "        )\n",
        "        print(f\"{key}: {parameter_accuracy:.4f}\")\n",
        "        start_idx = end_idx\n",
        "\n",
        "# Train the model and evaluate\n",
        "train_model(model, train_loader, test_loader, epochs=20)\n",
        "evaluate_predictions(model, test_loader)\n",
        "\n",
        "# Test prediction with example\n",
        "example_prompt = X_test[0]\n",
        "predicted = predict(example_prompt)\n",
        "print(\"\\nExample Prediction:\")\n",
        "print(\"Prompt:\", example_prompt)\n",
        "print(\"Predicted Parameters:\", predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804,
          "referenced_widgets": [
            "d77bf96dafed4b7abfd80da1c45a381f",
            "b33388d31b174eea8c1f74d53c944e44",
            "122f189628944b0f85a035791c045017",
            "3bed795a38534dcbbda0edcabfd7b31b",
            "ebf559b96c8c4c589ad15e0d0bc51950",
            "d46c2a2fce334342bbabb58e714f44f3",
            "da309f5bc8214b5cafb181d1527efc13",
            "f662f12c2423498797bab95aa1d7047f",
            "44fac15d71fe43dbb6d91c01db9b678b",
            "a7cfc75380284ae9a4e04157e02d1f1a",
            "371b91504c074eec936562f8a242a016",
            "213cda1150074c5986ed1abafbbf5de3",
            "caebc6ea49994f98a5ff2e68ffab445a",
            "8e9d9383e88046b2bfd1373840ce61e4",
            "93d5de0b8d4d4e73b23cec9b6acf17d5",
            "2858c0b7526140fca4d57f003ff79deb",
            "256434e44279475585bff4e3afcfcdef",
            "62885140128e4e4c8a962bc3b1b5ce49",
            "7e5afe6eb8de4ef4967dc386f2f6c94a",
            "84b31a402d47472fa6adb0c9ff28d452",
            "cdc6a1b577f9472ea85c1b49141671e8",
            "71b429bfca3842159159697b8dc91e65",
            "9272fa605df3452da3aa6040883b075c",
            "3bf8bddfed124a1ea051654578cd2df7",
            "daf1e8e2db304bbca84852bad613828e",
            "fcb1dbe02e784a3e85723b80d4f39e73",
            "ec6e1ec4892b40f2bc53b4a7293272b9",
            "5fd114b6adcc4d89b08e89003e79fb42",
            "4d167d184a5e4af08f232a767e23d1e9",
            "3fde1feca9c14d82b7950bca83a2e248",
            "abe4002fc92e482a8369c4c436da89f7",
            "35a38fb43a3344c4bcf6e404e448b2cd",
            "6e7dc3ad698347dcbd7a16b77da7e7e2",
            "85d2a0820ce647f696eed99159c36d40",
            "4e7ac9c2790e412bb265479f1db0d8f3",
            "9b481f9b6de6494ab380d0189f44791e",
            "ea35d283b1064987a8ccef72ad52c786",
            "827d9bf158a44b28ad0c23b555d7b3c0",
            "bff26a0ce5b740eea766131f8c2726d9",
            "2bb63054c49a46acbf6c540cd49a50ff",
            "297e3a72b5f44995912a84b4d34759e5",
            "3d19e344bde04309bb8165f7cf6ecb0f",
            "4f918ae83322488a8c8c81d53833eab2",
            "a3fc1287743b4827b997e4b10d5827d9",
            "1d391b7c295b4ffb8c9842b21c716b3e",
            "82d46bb83b8340c789eb29ade3761c42",
            "c992c381dc154f93ada98ca9648a1bfb",
            "ffe51079a5cf44f89f7a1600fccda371",
            "b9d4b36a9d694210a0f24af50aaf5708",
            "82505806c86e4d179a3263293ef526c8",
            "92dc6d6a6e1549f798f9d4e9af7dbe37",
            "68573ad36df14aa9839d906cd74ce08e",
            "f04f88d2d7054dd98173fca3aa4ee286",
            "b7109dbd350b4454a575f039d857643a",
            "b8e0ee71a6ef403284cf6f446366d339"
          ]
        },
        "id": "VtavftmAIoKI",
        "outputId": "721de7bb-9dcf-4ccd-85cf-3524845b10d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d77bf96dafed4b7abfd80da1c45a381f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "213cda1150074c5986ed1abafbbf5de3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9272fa605df3452da3aa6040883b075c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85d2a0820ce647f696eed99159c36d40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d391b7c295b4ffb8c9842b21c716b3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training Loss: 0.2986, Training Accuracy: 0.9067\n",
            "Validation Loss: 0.2771, Validation Accuracy: 0.9104\n",
            "--------------------------------------------------\n",
            "Epoch 2\n",
            "Training Loss: 0.2325, Training Accuracy: 0.9270\n",
            "Validation Loss: 0.1819, Validation Accuracy: 0.9487\n",
            "--------------------------------------------------\n",
            "Epoch 3\n",
            "Training Loss: 0.1609, Training Accuracy: 0.9528\n",
            "Validation Loss: 0.1342, Validation Accuracy: 0.9567\n",
            "--------------------------------------------------\n",
            "Epoch 4\n",
            "Training Loss: 0.1127, Training Accuracy: 0.9683\n",
            "Validation Loss: 0.0839, Validation Accuracy: 0.9836\n",
            "--------------------------------------------------\n",
            "Epoch 5\n",
            "Training Loss: 0.0768, Training Accuracy: 0.9831\n",
            "Validation Loss: 0.0647, Validation Accuracy: 0.9842\n",
            "--------------------------------------------------\n",
            "Epoch 6\n",
            "Training Loss: 0.0583, Training Accuracy: 0.9845\n",
            "Validation Loss: 0.0467, Validation Accuracy: 0.9857\n",
            "--------------------------------------------------\n",
            "Epoch 7\n",
            "Training Loss: 0.0396, Training Accuracy: 0.9892\n",
            "Validation Loss: 0.0257, Validation Accuracy: 0.9967\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict function\n",
        "def predict(prompt):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(prompt, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    input_ids, attention_mask = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask).cpu().numpy()[0]\n",
        "    predicted_params = {}\n",
        "    start_idx = 0\n",
        "    for key, values in parameter_keys.items():\n",
        "        end_idx = start_idx + len(values)\n",
        "        predicted_value_idx = np.argmax(outputs[start_idx:end_idx])\n",
        "        if outputs[start_idx:end_idx][predicted_value_idx] > 0.1:\n",
        "            predicted_params[key] = values[predicted_value_idx]\n",
        "        start_idx = end_idx\n",
        "    return predicted_params\n",
        "\n",
        "# Test prediction\n",
        "for x in X_test:\n",
        "    example_prompt = x\n",
        "    predicted = predict(example_prompt)\n",
        "    print(\"Prompt:\", example_prompt)\n",
        "    print(\"Predicted Parameters:\", predicted)\n",
        "    #print(\"Actual Parameters:\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YXaKAtXVZEW",
        "outputId": "7f950e4f-cd70-4331-a59e-213b456faca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Position the camera for a straight-on extreme close-up, placing the subject rightmost edge and capturing their right side. The shot should track forward uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'right', 'CameraMovementType': 'dollyIn'}\n",
            "Prompt: Capture a full shot shot from a bird's eye angle, with the subject positioned very top and viewed from the from the right. The camera angle up slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'fullShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'right', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: From a high-angle perspective, execute a very long shot with the subject topmost edge in frame, showing their angled back left. Use a track left movement at a gradually decelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: From a high-angle perspective, execute a macro shot with the subject top area in frame, showing their diagonal front left. Use a angle up movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'top', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: From a top-down perspective, execute a extreme wide with the subject bottom area in frame, showing their partial front right. Use a tilt left movement at a steady pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Capture a head to toe shot from a straight-on angle, with the subject positioned very bottom and viewed from the left side. The camera tilt right uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'left', 'CameraMovementType': 'static'}\n",
            "Prompt: Capture a detail view shot from a neutral angle, with the subject positioned southwest position and viewed from the right profile. The camera boom up steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'right', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a from below close-up, placing the subject northeast position and capturing their front view. The shot should move backward rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'front', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: From a high-angle perspective, execute a bust shot with the subject lower portion in frame, showing their partial back right. Use a contra-zoom in movement at a picking up pace pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a far overhead perspective, execute a full shot with the subject right portion in frame, showing their diagonal front left. Use a slide left movement at a uniform pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'right', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Position the camera for a upward-facing very long shot, placing the subject bottom right corner and capturing their partial back right. The shot should tilt left rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Position the camera for a straight-on bust shot, placing the subject at the bottom and capturing their angled front right. The shot should still gradually accelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'static'}\n",
            "Prompt: From a neutral perspective, execute a bust shot with the subject at the top in frame, showing their right side. Use a jib down movement at a rhythmic stopping pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'top', 'SubjectView': 'right', 'CameraMovementType': 'craneDown'}\n",
            "Prompt: Capture a waist shot shot from a top-down angle, with the subject positioned at the bottom and viewed from the front view. The camera slide right start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'front', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Capture a tight shot shot from a overhead angle, with the subject positioned left side and viewed from the from the left. The camera pan left punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'closeUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'left', 'SubjectView': 'left', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Position the camera for a bird's eye full shot, placing the subject top area and capturing their from the left. The shot should fixed steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'top', 'SubjectView': 'left', 'CameraMovementType': 'static'}\n",
            "Prompt: From a upward-facing perspective, execute a full shot with the subject southeast position in frame, showing their front view. Use a contra-zoom out movement at a uniform pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'front', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a high-angle perspective, execute a very wide shot with the subject extreme bottom in frame, showing their angled front left. Use a sweep right movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'panRight'}\n",
            "Prompt: Position the camera for a aerial macro shot, placing the subject extreme top and capturing their diagonal front left. The shot should pull out measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: From a high-angle perspective, execute a very long shot with the subject upper portion in frame, showing their from the left. Use a orbit right movement at a gradually decelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'top', 'SubjectView': 'left', 'CameraMovementType': 'arcRight'}\n",
            "Prompt: Capture a full shot shot from a overhead angle, with the subject positioned rightmost edge and viewed from the partial back left. The camera slide right punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'truckRight'}\n",
            "Prompt: From a eye-level perspective, execute a close-up with the subject bottom area in frame, showing their from the left. Use a lateral right movement at a intermittent pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'left', 'CameraMovementType': 'truckRight'}\n",
            "Prompt: Capture a near view shot from a from below angle, with the subject positioned bottom left corner and viewed from the rear view. The camera fixed picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'back', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a bust shot shot from a upward-facing angle, with the subject positioned top right corner and viewed from the angled back left. The camera circular left rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'right', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: Position the camera for a overhead very wide shot, placing the subject northeast position and capturing their diagonal front left. The shot should diagonal right uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Position the camera for a upward-facing panoramic view, placing the subject top area and capturing their diagonal back left. The shot should boom up slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'top', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a full body shot from a downward-facing angle, with the subject positioned in the center and viewed from the direct front. The camera curve right rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'fullShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'center', 'SubjectView': 'front', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a full shot shot from a eye-level angle, with the subject positioned bottommost edge and viewed from the left side. The camera tilt right decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'fullShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'left', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: From a aerial perspective, execute a detail view with the subject northeast position in frame, showing their left side. Use a lower movement at a slowing down pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'center', 'SubjectView': 'left', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: From a from above perspective, execute a head to toe with the subject lower right in frame, showing their from the right. Use a move down movement at a intentional stops pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'fullShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'right'}\n",
            "Prompt: Capture a medium shot shot from a overhead angle, with the subject positioned extreme left and viewed from the right profile. The camera track forward steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'right', 'CameraMovementType': 'dollyIn'}\n",
            "Prompt: Capture a very wide shot shot from a far overhead angle, with the subject positioned right side and viewed from the partial front right. The camera tilt right uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'right', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Position the camera for a high-angle tight shot, placing the subject lower left and capturing their direct front. The shot should maintain follow slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'front', 'CameraMovementType': 'follow'}\n",
            "Prompt: Capture a close-up shot from a neutral angle, with the subject positioned in the center and viewed from the left side. The camera pan right intentional stops.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'center', 'SubjectView': 'left', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a establishing shot shot from a aerial angle, with the subject positioned in the center and viewed from the right profile. The camera lower down intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'center', 'SubjectView': 'right', 'CameraMovementType': 'pedestalDown'}\n",
            "Prompt: From a far overhead perspective, execute a waist shot with the subject left portion in frame, showing their diagonal back right. Use a pull back and zoom movement at a steady pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'dollyOutZoomIn'}\n",
            "Prompt: From a far overhead perspective, execute a full view with the subject northeast position in frame, showing their diagonal front right. Use a raise up movement at a start and stop pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'longShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'tiltUp'}\n",
            "Prompt: Position the camera for a upward-facing detail view, placing the subject extreme top and capturing their rear view. The shot should lower down punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'back', 'CameraMovementType': 'pedestalDown'}\n",
            "Prompt: Capture a detail view shot from a from directly above angle, with the subject positioned bottom area and viewed from the diagonal front left. The camera circular right measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a waist shot shot from a straight-on angle, with the subject positioned northeast position and viewed from the right profile. The camera roll right start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'right', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Position the camera for a upward-facing mid-shot, placing the subject middle and capturing their direct front. The shot should circular right slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'center', 'SubjectView': 'front'}\n",
            "Prompt: From a downward-facing perspective, execute a extreme wide with the subject southwest position in frame, showing their from the right. Use a lateral left movement at a gradually accelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'right', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Position the camera for a top-down full shot, placing the subject rightmost edge and capturing their diagonal front right. The shot should lift up intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Position the camera for a overhead wide shot, placing the subject lower right and capturing their angled back left. The shot should track backward measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'top', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: From a from above perspective, execute a very wide shot with the subject rightmost edge in frame, showing their front view. Use a diagonal right movement at a consistent speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'front', 'CameraMovementType': 'panRight'}\n",
            "Prompt: Position the camera for a aerial very wide shot, placing the subject rightmost edge and capturing their diagonal back left. The shot should track subject intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'follow'}\n",
            "Prompt: From a low-angle perspective, execute a close-up with the subject very top in frame, showing their from behind. Use a angle up movement at a increasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'back', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a upward-facing bust shot, placing the subject at the bottom and capturing their angled front left. The shot should fixed decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'static'}\n",
            "Prompt: Position the camera for a top-down mid-shot, placing the subject middle and capturing their angled front right. The shot should rotate left gradually decelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Capture a long shot shot from a far overhead angle, with the subject positioned lower right and viewed from the partial back right. The camera roll left increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'longShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Capture a full body shot from a top-down angle, with the subject positioned at the bottom and viewed from the front view. The camera sweep right consistent speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'front', 'CameraMovementType': 'pedestalUp'}\n",
            "Prompt: Capture a tight shot shot from a neutral angle, with the subject positioned lower right and viewed from the rear view. The camera diagonal left picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'back', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: From a low-angle perspective, execute a medium close-up with the subject very bottom in frame, showing their left side. Use a lateral left movement at a punctuated movement pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'left', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Position the camera for a top-down medium shot, placing the subject rightmost edge and capturing their diagonal front right. The shot should jib up intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Position the camera for a straight-on extreme wide, placing the subject extreme bottom and capturing their from the right. The shot should move backward decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'right', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a from directly above medium close-up, placing the subject southeast position and capturing their from the right. The shot should elevate slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'right', 'CameraMovementType': 'pedestalUp'}\n",
            "Prompt: From a bird's eye perspective, execute a extreme close-up with the subject lower left in frame, showing their back view. Use a track left movement at a measured pauses pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'back', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Capture a long shot shot from a far overhead angle, with the subject positioned left portion and viewed from the diagonal back left. The camera push in gradually decelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'longShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Capture a bust shot shot from a top-down angle, with the subject positioned very bottom and viewed from the diagonal front right. The camera slide left decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Capture a head and shoulders shot from a from directly above angle, with the subject positioned right portion and viewed from the diagonal back left. The camera angle down intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'right', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a bird's eye extreme close-up, placing the subject rightmost edge and capturing their left side. The shot should tilt upward rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'left', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: From a from directly above perspective, execute a mid-shot with the subject at the bottom in frame, showing their direct front. Use a pan left movement at a gradually decelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'front', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Capture a full view shot from a overhead angle, with the subject positioned southwest position and viewed from the front view. The camera diagonal right increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'front', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: From a high-angle perspective, execute a full body with the subject bottom area in frame, showing their diagonal back left. Use a chase movement movement at a picking up pace pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'fullShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'follow'}\n",
            "Prompt: From a from directly above perspective, execute a wide shot with the subject in the center in frame, showing their from the right. Use a diagonal left movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'center', 'SubjectView': 'right', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Position the camera for a from below head to toe, placing the subject top left corner and capturing their partial front right. The shot should diagonal right consistent speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a extreme long shot shot from a from below angle, with the subject positioned extreme left and viewed from the right profile. The camera tilt downward increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'right', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Capture a head to toe shot from a from below angle, with the subject positioned bottom area and viewed from the from behind. The camera lower measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'fullShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'back', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a very wide shot shot from a high-angle angle, with the subject positioned middle and viewed from the back view. The camera roll right rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'center', 'SubjectView': 'back', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a tight shot shot from a from above angle, with the subject positioned extreme right and viewed from the angled front right. The camera track left punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'closeUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Position the camera for a bird's eye extreme long shot, placing the subject left portion and capturing their partial back left. The shot should track forward picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dollyIn'}\n",
            "Prompt: Position the camera for a from directly above establishing shot, placing the subject upper right and capturing their angled front right. The shot should move forward uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a top-down perspective, execute a medium shot with the subject top area in frame, showing their from the right. Use a contra-zoom out movement at a intermittent pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'top', 'SubjectView': 'right', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Capture a very long shot shot from a neutral angle, with the subject positioned at the bottom and viewed from the back view. The camera orbit right intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'back', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Position the camera for a straight-on medium shot, placing the subject extreme right and capturing their angled front left. The shot should slide right measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'truckRight'}\n",
            "Prompt: From a from below perspective, execute a long shot with the subject leftmost edge in frame, showing their diagonal back left. Use a jib up movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'longShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a close-up shot from a bird's eye angle, with the subject positioned southeast position and viewed from the back view. The camera curve left increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'back', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: From a from above perspective, execute a full body with the subject extreme top in frame, showing their partial back right. Use a contra-zoom out movement at a start and stop pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Position the camera for a low-angle establishing shot, placing the subject northwest position and capturing their left side. The shot should look up measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'left', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a medium shot shot from a from directly above angle, with the subject positioned lower left and viewed from the facing camera. The camera curve left steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'front', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: From a eye-level perspective, execute a establishing shot with the subject extreme left in frame, showing their diagonal back left. Use a jib up movement at a gradually decelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a bust shot shot from a top-down angle, with the subject positioned middle and viewed from the from the left. The camera push in and zoom out picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'center', 'SubjectView': 'left', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a far overhead perspective, execute a establishing shot with the subject extreme top in frame, showing their angled back left. Use a maintain follow movement at a gradually accelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'follow'}\n",
            "Prompt: From a downward-facing perspective, execute a detail view with the subject extreme left in frame, showing their angled front right. Use a compensating push movement at a rhythmic stopping pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Capture a mid-shot shot from a from below angle, with the subject positioned central position and viewed from the angled front left. The camera slide right increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'panRight'}\n",
            "Prompt: From a low-angle perspective, execute a full body with the subject northwest position in frame, showing their diagonal back left. Use a pan right movement at a gradually decelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'fullShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'panRight'}\n",
            "Prompt: Position the camera for a high-angle extreme wide, placing the subject at the bottom and capturing their rear view. The shot should tilt downward decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'back', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Capture a waist shot shot from a high-angle angle, with the subject positioned top right corner and viewed from the diagonal front right. The camera lower consistent speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'tiltUp'}\n",
            "Prompt: From a downward-facing perspective, execute a establishing shot with the subject central position in frame, showing their angled front left. Use a curve left movement at a gradually accelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: Position the camera for a from below macro shot, placing the subject rightmost edge and capturing their facing camera. The shot should stationary slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'front', 'CameraMovementType': 'static'}\n",
            "Prompt: Position the camera for a far overhead close-up, placing the subject lower left and capturing their partial front right. The shot should contra-zoom in gradually decelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a overhead perspective, execute a very wide shot with the subject rightmost edge in frame, showing their angled back left. Use a angle up movement at a measured pauses pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'tiltUp'}\n",
            "Prompt: Position the camera for a high-angle macro shot, placing the subject bottommost edge and capturing their from the right. The shot should pull out uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'right', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a top-down near view, placing the subject left side and capturing their angled front right. The shot should jib down increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Capture a medium shot shot from a downward-facing angle, with the subject positioned upper right and viewed from the diagonal back left. The camera maintain follow increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'follow'}\n",
            "Prompt: Capture a wide shot shot from a overhead angle, with the subject positioned extreme left and viewed from the from the left. The camera lateral right gradually decelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'left', 'CameraMovementType': 'truckRight'}\n",
            "Prompt: Position the camera for a overhead detail view, placing the subject lower right and capturing their front view. The shot should boom up measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'front', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: From a top-down perspective, execute a full shot with the subject lower right in frame, showing their diagonal front left. Use a tilt right movement at a rhythmic stopping pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'fullShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: From a straight-on perspective, execute a medium close-up with the subject rightmost edge in frame, showing their front view. Use a tilt left movement at a start and stop pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'front', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: Capture a full view shot from a upward-facing angle, with the subject positioned at the top and viewed from the left side. The camera pull out start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'longShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'top', 'SubjectView': 'left', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a eye-level close-up, placing the subject on the left and capturing their from the right. The shot should elevate gradually accelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'left', 'SubjectView': 'right', 'CameraMovementType': 'pedestalUp'}\n",
            "Prompt: Capture a tight shot shot from a straight-on angle, with the subject positioned bottommost edge and viewed from the rear view. The camera move down steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'back', 'CameraMovementType': 'craneDown'}\n",
            "Prompt: Position the camera for a neutral mid-shot, placing the subject right side and capturing their from the right. The shot should roll right decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'right', 'SubjectView': 'right', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a medium close-up shot from a from below angle, with the subject positioned at the bottom and viewed from the partial back left. The camera sweep right intentional stops.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Position the camera for a from above full shot, placing the subject leftmost edge and capturing their left profile. The shot should track forward steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'left', 'CameraMovementType': 'dollyIn'}\n",
            "Prompt: From a aerial perspective, execute a detail view with the subject in the center in frame, showing their from behind. Use a lower movement at a intermittent pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'center', 'SubjectView': 'back', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a low-angle full view, placing the subject top area and capturing their diagonal back left. The shot should look down punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'longShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'top', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'tiltUp'}\n",
            "Prompt: Position the camera for a eye-level full body, placing the subject extreme top and capturing their back view. The shot should contra-zoom in intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'back', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a straight-on perspective, execute a establishing shot with the subject right side in frame, showing their left side. Use a fixed movement at a gradually decelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'right', 'SubjectView': 'left', 'CameraMovementType': 'static'}\n",
            "Prompt: Capture a detail view shot from a top-down angle, with the subject positioned northwest position and viewed from the right profile. The camera orbit right picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'right', 'CameraMovementType': 'arcRight'}\n",
            "Prompt: Capture a wide shot shot from a from directly above angle, with the subject positioned far left and viewed from the diagonal front left. The camera curve left intentional stops.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: Position the camera for a bird's eye head to toe, placing the subject top area and capturing their right profile. The shot should maintain follow increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'fullShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'top', 'SubjectView': 'right', 'CameraMovementType': 'follow'}\n",
            "Prompt: Position the camera for a from above medium shot, placing the subject southwest position and capturing their partial front left. The shot should track backward measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a overhead medium shot, placing the subject on the right and capturing their right side. The shot should slide right increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'right', 'SubjectView': 'right', 'CameraMovementType': 'panRight'}\n",
            "Prompt: From a aerial perspective, execute a full body with the subject bottom area in frame, showing their right profile. Use a track subject movement at a gradually accelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'fullShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'right', 'CameraMovementType': 'follow'}\n",
            "Prompt: Position the camera for a far overhead establishing shot, placing the subject left portion and capturing their facing camera. The shot should jib up intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'left', 'SubjectView': 'front', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a from directly above wide shot, placing the subject northeast position and capturing their partial back right. The shot should move down consistent speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Position the camera for a overhead very wide shot, placing the subject extreme right and capturing their left side. The shot should push in and zoom out consistent speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'left', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Capture a close-up shot from a neutral angle, with the subject positioned middle and viewed from the angled front left. The camera sweep left measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Position the camera for a aerial head and shoulders, placing the subject bottommost edge and capturing their diagonal front left. The shot should track left increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: From a eye-level perspective, execute a waist shot with the subject middle in frame, showing their diagonal front right. Use a roll right movement at a intermittent pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: From a from above perspective, execute a bust shot with the subject central position in frame, showing their rear view. Use a contra-zoom in movement at a punctuated movement pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'center', 'SubjectView': 'back'}\n",
            "Prompt: Capture a close-up shot from a far overhead angle, with the subject positioned very top and viewed from the partial front left. The camera rotate right decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'pedestalDown'}\n",
            "Prompt: Capture a full view shot from a straight-on angle, with the subject positioned left side and viewed from the diagonal front left. The camera roll right measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'longShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a macro shot shot from a neutral angle, with the subject positioned upper portion and viewed from the back view. The camera diagonal right picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'top', 'SubjectView': 'back', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a head and shoulders shot from a aerial angle, with the subject positioned extreme right and viewed from the partial back right. The camera curve left picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Capture a wide shot shot from a downward-facing angle, with the subject positioned rightmost edge and viewed from the from the left. The camera move down consistent speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'longShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'left', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Capture a establishing shot shot from a from above angle, with the subject positioned right side and viewed from the partial front right. The camera contra-zoom in steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'right', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Position the camera for a top-down long shot, placing the subject top right corner and capturing their right side. The shot should tilt left punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'right', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Capture a long shot shot from a overhead angle, with the subject positioned northeast position and viewed from the angled front left. The camera pan left measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: Capture a close-up shot from a upward-facing angle, with the subject positioned northwest position and viewed from the from the right. The camera pan left measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'right', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: From a from directly above perspective, execute a bust shot with the subject bottom area in frame, showing their angled front right. Use a angle up movement at a steady pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'pedestalUp'}\n",
            "Prompt: Capture a near view shot from a far overhead angle, with the subject positioned southeast position and viewed from the rear view. The camera push in and zoom out increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'back', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a high-angle perspective, execute a full view with the subject in the center in frame, showing their diagonal front right. Use a descend movement at a punctuated movement pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'longShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'pedestalDown'}\n",
            "Prompt: From a downward-facing perspective, execute a head and shoulders with the subject lower portion in frame, showing their partial front left. Use a pull out movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: From a aerial perspective, execute a extreme close-up with the subject left portion in frame, showing their angled back left. Use a angle down movement at a consistent speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterBackLeft'}\n",
            "Prompt: Capture a medium close-up shot from a downward-facing angle, with the subject positioned extreme top and viewed from the from the left. The camera descend measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'left', 'CameraMovementType': 'pedestalDown'}\n",
            "Prompt: From a neutral perspective, execute a medium shot with the subject left portion in frame, showing their left side. Use a contra-zoom out movement at a steady pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'left', 'SubjectView': 'left', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Position the camera for a eye-level extreme close-up, placing the subject far right and capturing their angled front right. The shot should contra-zoom out increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Position the camera for a high-angle panoramic view, placing the subject extreme bottom and capturing their back view. The shot should rise up start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'back', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a neutral medium close-up, placing the subject leftmost edge and capturing their from the left. The shot should push in and zoom out uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerLeft', 'SubjectView': 'left', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Position the camera for a top-down head to toe, placing the subject southeast position and capturing their back view. The shot should circular left start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'left', 'SubjectView': 'back', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: From a neutral perspective, execute a full body with the subject northwest position in frame, showing their left profile. Use a tilt downward movement at a consistent speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'center', 'SubjectView': 'left', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: From a aerial perspective, execute a tight shot with the subject upper portion in frame, showing their direct front. Use a track forward movement at a picking up pace pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'top', 'SubjectView': 'front', 'CameraMovementType': 'dollyIn'}\n",
            "Prompt: Capture a mid-shot shot from a neutral angle, with the subject positioned very bottom and viewed from the right profile. The camera slide right punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'right', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: From a low-angle perspective, execute a full body with the subject northwest position in frame, showing their from behind. Use a tilt downward movement at a uniform pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'fullShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'back', 'CameraMovementType': 'craneDown'}\n",
            "Prompt: From a neutral perspective, execute a full body with the subject left side in frame, showing their angled back right. Use a roll right movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'fullShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a tight shot shot from a from below angle, with the subject positioned bottom area and viewed from the from the right. The camera push in start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'right', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a from above establishing shot, placing the subject in the center and capturing their angled back right. The shot should sweep left rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Capture a extreme wide shot from a top-down angle, with the subject positioned topmost edge and viewed from the diagonal front left. The camera slide right gradually decelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'truckRight'}\n",
            "Prompt: Capture a full body shot from a neutral angle, with the subject positioned at the bottom and viewed from the direct front. The camera roll left picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'fullShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'front', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Capture a head to toe shot from a aerial angle, with the subject positioned left portion and viewed from the angled front left. The camera boom down start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a head to toe shot from a overhead angle, with the subject positioned in the center and viewed from the diagonal back left. The camera move down rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'fullShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterBackLeft'}\n",
            "Prompt: From a downward-facing perspective, execute a medium shot with the subject very top in frame, showing their back view. Use a orbit left movement at a uniform pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'back', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: Position the camera for a far overhead detail view, placing the subject on the left and capturing their from behind. The shot should boom down start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'left', 'SubjectView': 'back'}\n",
            "Prompt: From a eye-level perspective, execute a extreme long shot with the subject very top in frame, showing their back view. Use a boom down movement at a measured pauses pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'back', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: Position the camera for a overhead head and shoulders, placing the subject far right and capturing their right side. The shot should boom up decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'right', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a eye-level near view, placing the subject top left corner and capturing their direct front. The shot should maintain follow decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'front', 'CameraMovementType': 'follow'}\n",
            "Prompt: From a upward-facing perspective, execute a full shot with the subject middle in frame, showing their angled back left. Use a jib up movement at a punctuated movement pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'center', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a overhead close-up, placing the subject right side and capturing their left side. The shot should compensating push increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'closeUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'right', 'SubjectView': 'left', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: From a bird's eye perspective, execute a long shot with the subject lower portion in frame, showing their angled back left. Use a rotate right movement at a intentional stops pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'longShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a extreme wide shot from a from above angle, with the subject positioned very bottom and viewed from the from the right. The camera lower gradually accelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'right', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Position the camera for a upward-facing extreme wide, placing the subject top right corner and capturing their back view. The shot should pull out slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'back', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: From a bird's eye perspective, execute a head and shoulders with the subject top left corner in frame, showing their rear view. Use a boom up movement at a gradually decelerating pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'back', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Capture a establishing shot shot from a eye-level angle, with the subject positioned left portion and viewed from the angled back right. The camera pull out start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a far overhead very wide shot, placing the subject top area and capturing their angled front left. The shot should fixed gradually decelerating.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'top', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'static'}\n",
            "Prompt: From a aerial perspective, execute a extreme close-up with the subject southwest position in frame, showing their from behind. Use a push in and zoom out movement at a intentional stops pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'back', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Capture a near view shot from a from below angle, with the subject positioned northwest position and viewed from the right profile. The camera move down slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'right', 'CameraMovementType': 'pedestalDown'}\n",
            "Prompt: From a eye-level perspective, execute a near view with the subject rightmost edge in frame, showing their diagonal front left. Use a roll right movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Capture a mid-shot shot from a low-angle angle, with the subject positioned top right corner and viewed from the partial back right. The camera track subject intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'follow'}\n",
            "Prompt: Position the camera for a from above panoramic view, placing the subject bottom area and capturing their diagonal front right. The shot should lift up intentional stops.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'pedestalUp'}\n",
            "Prompt: Position the camera for a from above extreme wide, placing the subject topmost edge and capturing their right side. The shot should boom down picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'right', 'CameraMovementType': 'craneDown'}\n",
            "Prompt: From a aerial perspective, execute a panoramic view with the subject southeast position in frame, showing their from behind. Use a diagonal right movement at a start and stop pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'back', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: From a from above perspective, execute a close-up with the subject at the top in frame, showing their angled back left. Use a roll right movement at a start and stop pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'closeUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'top', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: From a low-angle perspective, execute a close-up with the subject extreme top in frame, showing their partial front right. Use a lower movement at a start and stop pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: From a high-angle perspective, execute a long shot with the subject top left corner in frame, showing their angled front left. Use a diagonal right movement at a picking up pace pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'longShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dutchRight'}\n",
            "Prompt: Position the camera for a downward-facing detail view, placing the subject very bottom and capturing their angled back right. The shot should angle down punctuated movement.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'tiltDown'}\n",
            "Prompt: Capture a head and shoulders shot from a far overhead angle, with the subject positioned on the right and viewed from the partial front right. The camera tilt left rhythmic stopping.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterFrontRight', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Capture a long shot shot from a top-down angle, with the subject positioned upper left and viewed from the left profile. The camera lateral right start and stop.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'longShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'left', 'CameraMovementType': 'truckRight'}\n",
            "Prompt: From a downward-facing perspective, execute a long shot with the subject northeast position in frame, showing their diagonal back left. Use a sweep right movement at a steady pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'longShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'right', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'panRight'}\n",
            "Prompt: From a upward-facing perspective, execute a establishing shot with the subject extreme top in frame, showing their from the left. Use a lower movement at a intentional stops pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'left', 'CameraMovementType': 'craneUp'}\n",
            "Prompt: Position the camera for a upward-facing long shot, placing the subject northeast position and capturing their back view. The shot should descend increasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'longShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomRight', 'SubjectView': 'back'}\n",
            "Prompt: From a from below perspective, execute a bust shot with the subject extreme top in frame, showing their diagonal front left. Use a push in and zoom out movement at a picking up pace pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'mediumCloseUp', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Capture a panoramic view shot from a upward-facing angle, with the subject positioned at the top and viewed from the from behind. The camera pull out intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'back', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: From a from below perspective, execute a extreme close-up with the subject upper right in frame, showing their right profile. Use a angle down movement at a decreasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'right', 'CameraMovementType': 'craneDown'}\n",
            "Prompt: Position the camera for a far overhead establishing shot, placing the subject leftmost edge and capturing their from the left. The shot should track left uniform.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'left', 'SubjectView': 'left', 'CameraMovementType': 'arcLeft'}\n",
            "Prompt: Capture a tight shot shot from a neutral angle, with the subject positioned topmost edge and viewed from the partial back right. The camera still slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'outerTop', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'craneDown'}\n",
            "Prompt: Capture a very long shot shot from a top-down angle, with the subject positioned in the center and viewed from the from the right. The camera pull out consistent speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'center', 'SubjectView': 'right', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a overhead head to toe, placing the subject northwest position and capturing their angled front left. The shot should pan right intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'fullShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'topLeft', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'panRight'}\n",
            "Prompt: Position the camera for a overhead detail view, placing the subject extreme right and capturing their direct front. The shot should pan left intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'extremeCloseUp', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'front', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Position the camera for a from below tight shot, placing the subject upper right and capturing their right side. The shot should lateral left slowing down.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'low', 'ShotSize': 'closeUp', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'right', 'CameraMovementType': 'truckLeft'}\n",
            "Prompt: From a eye-level perspective, execute a close-up with the subject left portion in frame, showing their angled back left. Use a push in and zoom out movement at a rhythmic stopping pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'closeUp', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'left', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'dollyInZoomOut'}\n",
            "Prompt: Capture a waist shot shot from a downward-facing angle, with the subject positioned bottom left corner and viewed from the partial back left. The camera sweep left picking up pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'mediumShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'threeQuarterBackLeft', 'CameraMovementType': 'panLeft'}\n",
            "Prompt: Position the camera for a overhead establishing shot, placing the subject southwest position and capturing their angled front left. The shot should track forward measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'veryLongShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'bottom', 'SubjectView': 'threeQuarterFrontLeft', 'CameraMovementType': 'dollyIn'}\n",
            "Prompt: From a overhead perspective, execute a mid-shot with the subject bottommost edge in frame, showing their right profile. Use a pull out movement at a intermittent pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'mediumShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'right', 'CameraMovementType': 'dollyOut'}\n",
            "Prompt: Position the camera for a bird's eye panoramic view, placing the subject lower left and capturing their from behind. The shot should push in decreasing speed.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'fastToSlow', 'SubjectInFramePosition': 'bottomLeft', 'SubjectView': 'back', 'CameraMovementType': 'dollyIn'}\n",
            "Prompt: Capture a extreme long shot shot from a aerial angle, with the subject positioned right portion and viewed from the from the left. The camera maintain follow steady.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'birdsEye', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'constant', 'SubjectInFramePosition': 'right', 'SubjectView': 'left', 'CameraMovementType': 'follow'}\n",
            "Prompt: From a straight-on perspective, execute a medium shot with the subject rightmost edge in frame, showing their right profile. Use a diagonal left movement at a increasing speed pace.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'eye', 'ShotSize': 'mediumShot', 'MovementSpeed': 'slowToFast', 'SubjectInFramePosition': 'outerRight', 'SubjectView': 'right', 'CameraMovementType': 'dutchLeft'}\n",
            "Prompt: Position the camera for a top-down extreme wide, placing the subject upper right and capturing their from the right. The shot should fixed intermittent.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'overhead', 'ShotSize': 'extremeLongShot', 'MovementSpeed': 'stopAndGo', 'SubjectInFramePosition': 'topRight', 'SubjectView': 'right', 'CameraMovementType': 'static'}\n",
            "Prompt: Capture a head to toe shot from a downward-facing angle, with the subject positioned extreme bottom and viewed from the angled back right. The camera rotate right measured pauses.\n",
            "Predicted Parameters: {'CameraVerticalAngle': 'high', 'ShotSize': 'fullShot', 'MovementSpeed': 'deliberateStartStop', 'SubjectInFramePosition': 'outerBottom', 'SubjectView': 'threeQuarterBackRight', 'CameraMovementType': 'panRight'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traning (CLIP)"
      ],
      "metadata": {
        "id": "-Uh89mIWldDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "gxKQca2hleod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import clip\n",
        "import json\n",
        "import numpy as np\n",
        "from transformers import CLIPTokenizer\n",
        "\n",
        "# Load the dataset\n",
        "with open(\"generated_camera_prompts.json\", \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Extract prompts and parameters\n",
        "prompts = [item[\"prompt\"] for item in dataset]\n",
        "parameters = [item[\"parameters\"] for item in dataset]\n",
        "\n",
        "# Define all possible parameter keys and values (same as before)\n",
        "parameter_keys = {\n",
        "    \"CameraVerticalAngle\": [\"low\", \"eye\", \"high\", \"overhead\", \"birdsEye\"],\n",
        "    \"ShotSize\": [\n",
        "        \"extremeCloseUp\", \"closeUp\", \"mediumCloseUp\", \"mediumShot\",\n",
        "        \"fullShot\", \"longShot\", \"veryLongShot\", \"extremeLongShot\",\n",
        "    ],\n",
        "    \"MovementSpeed\": [\n",
        "        \"slowToFast\", \"fastToSlow\", \"constant\", \"stopAndGo\",\n",
        "        \"deliberateStartStop\",\n",
        "    ],\n",
        "    \"SubjectInFramePosition\": [\n",
        "        \"left\", \"right\", \"top\", \"bottom\", \"center\", \"topLeft\", \"topRight\",\n",
        "        \"bottomLeft\", \"bottomRight\", \"outerLeft\", \"outerRight\", \"outerTop\",\n",
        "        \"outerBottom\",\n",
        "    ],\n",
        "    \"SubjectView\": [\n",
        "        \"front\", \"back\", \"left\", \"right\", \"threeQuarterFrontLeft\",\n",
        "        \"threeQuarterFrontRight\", \"threeQuarterBackLeft\", \"threeQuarterBackRight\",\n",
        "    ],\n",
        "    \"CameraMovementType\": [\n",
        "        \"static\", \"panLeft\", \"panRight\", \"tiltUp\", \"tiltDown\", \"dollyIn\",\n",
        "        \"dollyOut\", \"truckLeft\", \"truckRight\", \"pedestalUp\", \"pedestalDown\",\n",
        "        \"arcLeft\", \"arcRight\", \"craneUp\", \"craneDown\", \"dollyOutZoomIn\",\n",
        "        \"dollyInZoomOut\", \"dutchLeft\", \"dutchRight\", \"follow\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# One-hot encode parameters (same as before)\n",
        "def encode_parameters(parameters):\n",
        "    encoded = []\n",
        "    for key, values in parameter_keys.items():\n",
        "        vec = [0] * len(values)\n",
        "        if key in parameters and parameters[key] in values:\n",
        "            vec[values.index(parameters[key])] = 1\n",
        "        encoded.extend(vec)\n",
        "    return encoded\n",
        "\n",
        "encoded_parameters = np.array([encode_parameters(p) for p in parameters])\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    prompts, encoded_parameters, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define a custom dataset for CLIP\n",
        "class CLIPCameraDataset(Dataset):\n",
        "    def __init__(self, prompts, labels, tokenizer, max_length=77):  # CLIP's max token length is 77\n",
        "        self.prompts = prompts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prompt = self.prompts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize with truncation and padding\n",
        "        encoding = self.tokenizer(\n",
        "            prompt,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            encoding.input_ids.squeeze(0),\n",
        "            encoding.attention_mask.squeeze(0),\n",
        "            torch.tensor(label, dtype=torch.float)\n",
        "        )\n",
        "\n",
        "# Initialize CLIP model and tokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = CLIPCameraDataset(X_train, y_train, tokenizer)\n",
        "test_dataset = CLIPCameraDataset(X_test, y_test, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define the model using CLIP's text encoder\n",
        "class CLIPCameraPredictor(nn.Module):\n",
        "    def __init__(self, clip_model, num_labels):\n",
        "        super(CLIPCameraPredictor, self).__init__()\n",
        "        self.clip = clip_model\n",
        "        self.text_projection = clip_model.text_projection\n",
        "\n",
        "        # Freeze CLIP parameters\n",
        "        for param in self.clip.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # New layers for parameter prediction\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc1 = nn.Linear(512, 256)  # CLIP's text embedding dimension is 512\n",
        "        self.fc2 = nn.Linear(256, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get CLIP text embeddings\n",
        "        text_features = self.clip.encode_text(input_ids)\n",
        "        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "        # Process through our layers\n",
        "        x = self.dropout(text_features)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "num_labels = y_train.shape[1]\n",
        "model = CLIPCameraPredictor(clip_model, num_labels)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.AdamW(\n",
        "    [p for p in model.parameters() if p.requires_grad],\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, test_loader, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for input_ids, attention_mask, labels in train_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for input_ids, attention_mask, labels in test_loader:\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "        print(f\"Validation Loss: {test_loss / len(test_loader):.4f}\")\n",
        "\n",
        "# Predict function\n",
        "def predict(prompt):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(\n",
        "        prompt,\n",
        "        max_length=77,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = encoding.input_ids.to(device)\n",
        "    attention_mask = encoding.attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask).cpu().numpy()[0]\n",
        "\n",
        "    predicted_params = {}\n",
        "    start_idx = 0\n",
        "    for key, values in parameter_keys.items():\n",
        "        end_idx = start_idx + len(values)\n",
        "        predicted_value_idx = np.argmax(outputs[start_idx:end_idx])\n",
        "        if outputs[start_idx:end_idx][predicted_value_idx] > 0.1:\n",
        "            predicted_params[key] = values[predicted_value_idx]\n",
        "        start_idx = end_idx\n",
        "    return predicted_params\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, test_loader, epochs=50)\n",
        "\n",
        "# Test prediction\n",
        "example_prompt = X_test[0]\n",
        "predicted = predict(example_prompt)\n",
        "print(\"Prompt:\", example_prompt)\n",
        "print(\"Predicted Parameters:\", predicted)\n",
        "print(\"Actual Parameters:\", y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "R3RkP_9VU3mW",
        "outputId": "ac4c0272-955d-4f79-9d41-bf7c6c3664ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Half and Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-681a6ff48fd0>\u001b[0m in \u001b[0;36m<cell line: 204>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;31m# Test prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-681a6ff48fd0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, epochs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-681a6ff48fd0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Process through our layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Half and Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = torch.sigmoid(model(batch_X)) > 0.5\n",
        "        correct += (outputs.numpy() == batch_y.numpy()).sum()\n",
        "        total += batch_y.numel()\n",
        "\n",
        "print(f\"Accuracy: {correct / total:.2%}\")\n"
      ],
      "metadata": {
        "id": "aGhbqyJ-ItJW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}